# 非线性优化

参考资料：

http://www.whudj.cn/?p=1122

https://cloud.tencent.com/developer/article/1390228

http://zhaoxuhui.top/blog/2018/04/04/ceres&ls.html#1%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%8E%9F%E7%90%86

https://gitee.com/jqf_zl/ceres_tutorial/blob/master/Ceres%20%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BC%98%E5%8C%96%E5%BA%93%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8.pdf

## 最小二乘问题

最小二乘问题如下式所示：
$$
\min_x\frac{1}{2}\sum_i\rho_i(||f_i(x_{i_1},x_{i_2},x_{i_3},\cdots,x_{i_k},) ||^2)\\
s.t\quad l_j\le x_j\le u_j
$$
即求解该式的最小值，像这种多参数矩阵运算的，通过求导使其导函数为零的方法是行不通的，一般采取的方法是迭代的方法，即使$f(x+\Delta x)\le f(x)$，不停的迭代从而得到一个收敛的结果。这样就出现了两个问题，一个是$\Delta x$的方向怎么确定，一个是$\Delta x$的大小如何确定。

## 梯度下降法

### 下降方向

考虑一个方向 和该方向的足够小的步长 ，通过泰勒展开我们得到
$$
F(x+ah)=F(x)+ah^Tg(x)+o(a^2)
$$
考虑到我们的目标是$F(x+ah)<F(x)$，那么得到如果方向满足
$$
h^Tg(x)=||h||\cdot||g(x)||\cdot\cos(\theta)<0
$$
则 h 为 x处的下降方向。

### 最速梯度下降法

当我们选取一个非负步长时，函数相对变化率为
$$
\lim_{a\rightarrow0}\frac{F(x)-F(x+ah)}{a|||h||}=-||g(x||\cdot\cos(\theta)
$$
当 $\theta=\pi$ 时，我们有最大的下降值，而此时的下降方向就是负梯度方向。

梯度下降法存在的问题：

1. 初始值会影响迭代次数和结果
2. 我们只提了方向，那么步长该如何选择呢

### 线搜索方法

这里说的线搜索方法只是一个策略

我们知道，针对最速梯度下降法，我们不但需要知道变量的迭代方向，还需要知道变量更新的值具体是
多少，我们定义  $\phi(a)=F(x+ah),x\ and\ h\ fixed$。

<img src="https://images0.cnblogs.com/blog/326731/201311/11172826-3eca9ab23e8d4815894a5d5b60cc449a.png" alt="img" style="zoom:80%;" />

当给定一个初始的 $a$ 时，上图给出了一种可能的函数形式，我们可以得到可能存在的几种状态：

1. $a$过小，函数的变化值太小，这时我们需要增大$a$
2. $a$过大，$\phi(a)>\phi(0)$ , 需要减小$a$
3. $a$接近最小值，接受

如上图所示，事实上我们取得$a$最好是在 tangent 与 desired slope 之间，非精确线搜索便是这个思路：

1. $\phi(a_s)\le\phi(0)+\gamma_1*\phi^`(0)*a$，这里$0<\gamma_1<1$这个条件保证了不会出现上述的状态2
2. $\phi^`(a_s)\ge\gamma_2*\phi^`(0)$，这里$\gamma_1<\gamma_2<1$，这个条件保证了选取点不会离初始点太近，即避免了状态1

### 牛顿法

我们来看一下基本牛顿法

基本牛顿法是一种是用导数的算法，它每一步的迭代方向都是沿着当前点函数值下降的方向

我们主要集中讨论在一维的情形，对于一个需要求解的优化函数
$$
f(x)
$$
求函数的极值的问题可以转化为求导函数
$$
f^`(x)=0
$$
对函数$f(x)$进行泰勒展开到二阶，得到
$$
f(x)=f(x_k)+f^`(x_k)(x-x_k)+\frac12f^{``}(x_k)(x-x_k)^2
$$
对上式求导并令其为0，则
$$
f^`(x_k)+f^{``}(x_k)(x-x_k)=0
$$
即得到
$$
x=x_k-\frac{f^`(x_k)}{f^{``}(x_k)}
$$
这就是牛顿法的更新公式。

下面看一下完整的牛顿法

![image-20220111205122194](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220111205122194.png)

----

问题在于，如果H是负定的，且附近有一个局部最大值，牛顿法可能会收敛至该局部最大值。我们可以要求损失函数每一步都是减小的，或者使用如下的混合方法

![image-20220111205213954](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220111205213954.png)

牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。

### 高斯牛顿法

我们来看高斯牛顿法是怎么对牛顿法进行简化的。

将在牛顿法中，我们是将目标函数 $||f(x+\Delta x)||^2$ 展开，这里我们考虑直接将函数 $f(x)$ 进行泰勒展开, 并忽略高阶项
$$
f(x+\Delta x)=f(x)+J(x)h
$$
将上式代入我们的目标函数，则问题转化为
$$
arg\min_{\Delta x}||f(x)+J(x)h ||^2
$$
将目标函数展开，用一个符号来表示它
$$
L(h)=||f(x)+J(x)h ||^2=||f(x)||^2+2f(x)^TJh+h^TJ^TJh
$$
对上式h求导有
$$
L^`=J^TJh+J^Tf(x)\\
L^{``}=J^TJ
$$
<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220111211835499.png" alt="image-20220111211835499" style="zoom:80%;" />

高斯牛顿法有效的使用了一阶雅可比矩阵来替代了牛顿法的二阶海森矩阵的求解，降低了计算量，但是其也存在一些问题：

1. 要求$J^TJ$正定，这个条件时常会不满足
2. 我们知道泰勒展开本身只对 附近的区域才会有效果，一旦步长较大，近似实际上已经失效了

### LM算法

Levenberg-Marquart 算法是对上述缺点的改进。L-M方法是对梯度下降法与高斯-牛顿法进行线性组合以充分利用两种算法的优势。通过在Hessian矩阵中加入阻尼系数λ来控制每一步迭代的步长以及方向：

LM 只做了一个很简单的改进，其修正高斯牛顿法的步长为：
$$
h=-(J^TJ+\mu I)^{-1}*(J^Tf(x)),\ \ \lambda>0
$$
虽然只是简单的改变，但是却带来了几个好处：

1. 对所有的 $\lambda>0$, $J^TJ+\lambda I$变成了正定的，从而保证了 h 是梯度下降的方向
2. 当λ增大时，H+λI趋向于λI，也就是梯度下降法给出的迭代方向；
3. 当λ减小时，H+λI趋向于H，也就是高斯-牛顿法给出的方向。

## Ceres-slover 学习

### 基础知识

#### 指针：

**指针**是一个变量，其值为另一个变量的地址，即，内存位置的直接地址。

也就是说我们可定义一个变量a

```c++
int a=10
int *b
    b=&a
 *b为指向地址的内容
 b为地址
```

我是这样理解的，将\*看作是一种运算符，\*变量可以看作是对变量进行指针化操作

#### const关键字

下面是一些使用`const`关键字的例子。

```c++
  int b = 500;  
  const int* a = &b;       [1] //代表指针指向一个整数，然后常数化
  int const *a = &b;       [2] //代表指针指向一个常数，然后变为整数 
  int* const a = &b;       [3] //代表一个常数为地址，然后指针化，变为指针变量，然后整数化
  const int* const a = &b;   [4]//代表一个常数为地址，然后指针化，变为指针变量，然后整数化，再常数化 
```

如果`const`位于星号左侧，则`const`就是用来修饰指针所指向的变量，即指针指向为常量；如果`const`位于星号的 右侧，const就是修饰指针本身，即指针本身是常量。因此，\[1\]和\[2\]的情况相同，都是指针所指向的内容为常量，这种情况下不允许对内容进行更改操作，如不能`*a = 3;`；\[3\]为指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如a++是错误的；\[4\]为指针本身和指向的内容均为常量。

另外`const`的一些强大的功能在于它在函数声明中的应用。在一个函数声明中，const可以修饰函数的返回值，或某个参数；对于成员函数，还可以修饰是整个函数。一般放在函数体后，形如：

这种一般用于如果一个成员函数的不会修改数据成员，那么最好将其声明为`const`，因为`const`成员函数中不允许对数据成员进行修改，如果修改，编译器将报错，这大大提高了程序的健壮性。

#### struct结构体构造函数

结构体也可以像类一样有构造函数，这样在新建一个结构体时，就对其进行了初始化。例如如下代码。

```c++
#include<iostream>

using namespace std;
//结构体定义结束后别忘了加封号
struct myStruct
{
  double x_,y_; 
//结构体的构造函数，传入x、y
  myStruct(double x,double y)
  {x_=x;
   y_=y;
  }};			//分号要注意

int main()
{//创建一个结构体的时候要写成指针形式，否则会报错
  myStruct* s1 = new myStruct(3.4,6.1);
//注意指针形式的调用成员变量是箭头，不是点
  cout<<s1->x_<<endl;
  cout<<s1->y_<<endl;
  return 0;
}
```

#### 模板函数

C++中可以使用模板函数来减少代码的重复率。模板函数简单来说就是实现了一个函数多种使用。模板函数可以传入整形、浮点型、甚至字符型都可以，只需要更改模板类型即可。

```c++
#include<iostream>

using namespace std;
//模板函数定义的标准开头
template <typename T>
T add(T a,T b)
{
  T sum = a+b;
  return sum;
}

int main()
{
//注意模板函数调用的方式，需要在函数名后面用尖括号制定模板类型
  double sum1 = add<double>(3.5,1.1);
  double sum2 = add<int>(5,4);
  string sum3 = add<string>("a","b");
  cout<<"Typename double "<<sum1<<endl;
  cout<<"Typename int "<<sum2<<endl;
  cout<<"Typename string "<<sum3<<endl;
  return 0;
}
```

#### 运算符重载

在C++中用`operator`关键字重载运算符。运算符重载为类的成员函数的一般格式为：

```c++
<函数类型> operator <运算符>(<参数表>)
{
		<函数体>
} 
```

调用成员函数运算符的格式如下：

```c++
<对象名>.operator <运算符>(<参数>)
它等价于
<对象名><运算符><参数>
```

例如：a+b等价于a.operator +(b)。一般情况下，我们采用运算符的习惯表达方式。

当运算符重载为类的成员函数时，函数的参数个数比原来的操作数要少一个（后置单目运算符除外），这是因为成员函数用this指针隐式地访问了类的一个对象，它充当了运算符函数最左边的操作数。因此：

-   (1) 双目运算符重载为类的成员函数时，函数只显式说明一个参数，该形参是运算符的右操作数。
-   (2) 前置单目运算符重载为类的成员函数时，不需要显式说明参数，即函数没有形参。
-   (3) 后置单目运算符重载为类的成员函数时，函数要带有一个整型形参。

下面是简单的示例。

```c++
#include<iostream>
using namespace std;
struct MyStruct
{
//声明一个结构体的成员变量
  double x; 
//结构体构造函数
  MyStruct(double x_)
  {
    x = x_;
  }
    
  //在结构体中重载+运算符
  //注意+左边的数字不需要显式指出，默认是在结构体中的成员变量
  double operator+(double y)
  {
    return x*2+y*2;
  }
};

int main()
{
//新建一个结构体，并以数字3初始化
  MyStruct* my = new MyStruct(3);
//注意重载运算符的使用方式，这里my是结构体指针，因此使用箭头使用成员函数，不是点
  double res = my->operator+(4);
//也可以利用星号将指针变成对象，这样就可以使用第二种调用方式了
  double res2 = *my+6;
  cout<<res<<endl;
  cout<<res2<<endl;
  return 0;
}
```

小括号重载用得最多的地方是“仿函数”。

#### 仿函数

仿函数又称函数对象，它本质上是一种具有函数特质的对象，它 重载了operator()运算符，我们可以像使用函数一样使用该对象。通过重载`()`运算符，实现类似于函数的功能。下面是结构体中仿函数的简单示例。

```c++
#include<iostream>

using namespace std;

struct Functor
{
//在结构体中重载括号运算符，构造仿函数
    bool operator()(double x, double y)
    {
      return x > y;
    }
};

int main()
{
  Functor* fun = new Functor();
  
  cout<<fun->operator()(4.9,6.9)<<endl;
  
  cout<<Functor()(6,4)<<endl;
  return 0;
}
```

当然，结合上面的内容，我们可以写出一个更加复杂、健全的仿函数出来如下。

```c++
#include<iostream>

using namespace std;
//在结构体中重载括号运算符，构造仿函数
struct Functor
{
	//成员变量
    double bias;
//构造函数
    Functor(double b)
    {
      bias = b;
    }
  
//模板仿函数
    template <typename T>
    bool operator()(const T &x, T &y) const
    {
      y = x + bias;
      return true;
    }
};

int main()
{
  Functor* fun = new Functor(1.2);
  double x=3.0,y;
  fun->operator()<double>(x,y);
  cout<<y<<endl;
  return 0;
}
```

## Ceres库的使用

Ceres solver 是谷歌开发的一款用于非线性优化的库，在谷歌的开源激光雷达slam项目cartographer中被大量使用。使用Ceres库主要有以下几个步骤。

-   第一步，构建cost fuction(代价函数)，也就是寻优的目标式，在优化问题中可以看作是目标函数
-   第二步，通过代价函数构建待求解的优化问题
-   第三步，配置求解器参数并求解问题

有如下函数模型

$$
y=e^{mx+c}
$$
现有很多x、y观测值，需要对这个函数进行最小二乘拟合。和刚刚类似，我们需要去思考代价函数应该怎么写，也即当代价函数最大或最小时，刚好满足我们的需求。因为我们是对曲线进行拟合，自然希望拟合地越准确越好。“准确”这个概念用数学语言描述就是拟合得到的y’与真实的y的差值，其越小越好。

$$
f_{cost}=y^`-y
$$


其中，y’是由我们估计出的参数算出来的估计值，y是观测值(真实值)，它们的差值反映了估计的模型在该点的拟合准确度。 这里需要说明的是，由于后面在使用的时候是代价函数的平方，因此这里是y’-y还是y-y’并不会影响最终的结果。

当然，仅仅使某一个点的残差最小显然是不够的。从整体而言，我们希望所有点的差值都越小越好，而不是某一个点很好，其余都很差。 把这个思想转换成“代价函数”，那么就是所有残差之和最小。 也就是说，只要优化这个函数，就可以使所有残差和最小，从而在整体上做到对曲线的最佳拟合。

但是仔细想想这里会有个小问题。那就是残差不一定都是正的，例如某个点的残差是0.5,而另一个点是-0.5。显然这两个点的估计都是有误差的。但是把两个点的残差求和却为0，是最优的拟合。这显然和我们的认知有偏差。我们其实需要的只是残差的“大小”或者说“幅度”，至于其到底是正还是负我们并不关心。因为不管正负，都是误差。同时，在求某一点的残差时，不同相减顺序也会带来不同的结果，如10-5和5-10。因此我们需要寻找的这个总体的代价函数应该满足这两个条件：

-   1.不受残差相减顺序的影响
-   2.反映各残差之和，不受正负影响

基于以上两个条件，我们可以想到两种办法，一是对每一个残差都取绝对值，二是对每一个残差都取平方。使用哪一个方法更加简便呢？显然是取平方。因为取绝对值还涉及到一个逻辑判断，取平方直接数值运算就可以了。这也就是最小二乘名字中“二乘”的由来，就是为了解决以上两个问题。

所以我们总的优化目标函数就是各个代价函数之和。因为这里我们不考虑有粗差点，不用对离群点进行剔除，因此核函数系数为1,可以忽略了。